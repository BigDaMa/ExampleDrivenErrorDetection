{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import math\n",
    "import datetime\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import re\n",
    "import jellyfish as jf\n",
    "import geocoder\n",
    "import time\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import os.path\n",
    "from subprocess import PIPE,Popen\n",
    "from collections import defaultdict\n",
    "from scipy import sparse\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numberAttributes = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirty = pd.read_csv(\"/home/felix/BlackOak/List_A/inputDB.csv\")\n",
    "clean = pd.read_csv(\"/home/felix/BlackOak/List_A/groundDB.csv\", dtype={'SSN': object, 'ZIP': object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distinct_values_per_column = []\n",
    "for column in range(len(dirty.columns)):\n",
    "    distinct_values_per_column.append(dict())\n",
    "\n",
    "max_length = [0.0] * len(dirty.columns)\n",
    "sum_length = np.array([0] * len(dirty.columns))\n",
    "N = len(dirty)\n",
    "\n",
    "for index, row in dirty.iterrows():\n",
    "    for column in range(len(dirty.columns)):\n",
    "        value = row[dirty.columns[column]]\n",
    "        distinct_values_per_column[column][value] = distinct_values_per_column[column].get(value, 0) + 1\n",
    "\n",
    "        \n",
    "        max_length[column] = max (max_length[column], len(str(value)))\n",
    "        sum_length[column] += len(str(value))\n",
    "avg_length = sum_length / float(N)\n",
    "\n",
    "for column in range(len(dirty.columns)):\n",
    "    for key, value in distinct_values_per_column[column].iteritems():\n",
    "        distinct_values_per_column[column][key] = value / float(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 13, 13, 21, 44, 21, 17, 29, 26, 41, 11, 9]\n"
     ]
    }
   ],
   "source": [
    "print max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[94306, 15048, 681, 31917, 84228, 12695, 5070, 18825, 14558, 9735, 47358, 13608]\n"
     ]
    }
   ],
   "source": [
    "number_distinct_values_per_column = []\n",
    "for column in range(len(dirty.columns)):\n",
    "    number_distinct_values_per_column.append(len(distinct_values_per_column[column]))\n",
    "print number_distinct_values_per_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False  True False ..., False  True False]\n",
      " [False False False ..., False False False]\n",
      " [False  True False ...,  True  True False]\n",
      " ..., \n",
      " [False  True False ..., False False False]\n",
      " [False  True  True ..., False False False]\n",
      " [False  True False ..., False  True False]]\n"
     ]
    }
   ],
   "source": [
    "ground_truth = dirty.values != clean.values #all real errors\n",
    "print ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_column_feature(clean, dirty, number_distinct_values_per_column, \\\n",
    "                            avg_length1, max_length1, distinct_values_per_column):\n",
    "    column_id = np.array([0] * len(clean) * len(clean.columns))\n",
    "    column_distinct_values = np.array([0] * len(clean) * len(clean.columns))\n",
    "    column_avg_length = np.array([0.0] * len(clean) * len(clean.columns))\n",
    "    column_max_length = np.array([0] * len(clean) * len(clean.columns))\n",
    "    current_value_fraction = np.array([0.0] * len(clean) * len(clean.columns))\n",
    "    current_value_length = np.array([0] * len(clean) * len(clean.columns))\n",
    "    current_row_avg_fraction = np.array([0.0] * len(clean) * len(clean.columns))\n",
    "    current_row_avg_length = np.array([0.0] * len(clean) * len(clean.columns))\n",
    "    \n",
    "    i = 0\n",
    "    for row in range(len(clean)):\n",
    "        \n",
    "        row_sum_length = 0.0\n",
    "        row_sum_fraction = 0.0\n",
    "        for column in range(len(clean.columns)):\n",
    "            row_sum_fraction += distinct_values_per_column[column].get(dirty.values[row][column], 0)\n",
    "            row_sum_length += len(str(dirty.values[row][column]))\n",
    "        row_avg_length = row_sum_length / len(clean.columns)\n",
    "        row_avg_fraction = row_sum_fraction / len(clean.columns)\n",
    "            \n",
    "        \n",
    "        for column in range(len(clean.columns)):\n",
    "            # attribute based\n",
    "            column_id[i] = column\n",
    "            column_distinct_values[i] = number_distinct_values_per_column[column]\n",
    "            column_avg_length[i] = avg_length1[column]\n",
    "            column_max_length[i] = max_length1[column]\n",
    "            # value based\n",
    "            current_value_fraction[i] = distinct_values_per_column[column].get(dirty.values[row][column], 0)\n",
    "            current_value_length[i] = len(str(dirty.values[row][column]))\n",
    "            # row based\n",
    "            current_row_avg_fraction[i] = row_avg_fraction\n",
    "            current_row_avg_length[i] = row_avg_length\n",
    "            \n",
    "            i += 1\n",
    "\n",
    "    schema = [\"col_id\",\"col_distinct_values\",\"col_avg_length\",\"col_max_length\",\\\n",
    "              \"val_fraction\",\"val_length\",\"row_avg_fraction\",\"row_avg_length\"]\n",
    "\n",
    "    return [column_id, column_distinct_values, column_avg_length, column_max_length, \\\n",
    "            current_value_fraction, current_value_length, \\\n",
    "            current_row_avg_fraction, current_row_avg_length], schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_target(clean, ground_truth):\n",
    "    target = np.array([False] * len(clean) * len(clean.columns))\n",
    "    \n",
    "    i = 0\n",
    "    for row in range(len(clean)):\n",
    "        for column in range(len(clean.columns)):\n",
    "            target[i] = ground_truth[row,column]\n",
    "            i += 1\n",
    "            \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = []\n",
    "\n",
    "column_features, schema_metadata = generate_column_feature(clean, dirty, \\\n",
    "                                          number_distinct_values_per_column, \\\n",
    "                                          avg_length, max_length, distinct_values_per_column)\n",
    "for i in range(len(column_features)):\n",
    "    features.append(column_features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['col_id', 'col_distinct_values', 'col_avg_length', 'col_max_length', 'val_fraction', 'val_length', 'row_avg_fraction', 'row_avg_length']\n"
     ]
    }
   ],
   "source": [
    "total_schema = []\n",
    "#total_schema.extend(schema_tools)\n",
    "total_schema.extend(schema_metadata)\n",
    "print total_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = generate_target(clean, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_matrix = np.column_stack(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1131672, 8)\n"
     ]
    }
   ],
   "source": [
    "print feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_data(feature_matrix, train_size = 0.00001):\n",
    "    train_len = train_size\n",
    "    test_len = feature_matrix.shape[0] - train_len\n",
    "    \n",
    "    if (train_size <= 1):\n",
    "        train_len = int(math.ceil(feature_matrix.shape[0] * train_size))\n",
    "        test_len = int(math.floor(feature_matrix.shape[0] * (1 - train_size)))\n",
    "    \n",
    "    msk = np.ones((train_len,))\n",
    "    msk = np.concatenate((msk, np.zeros((test_len,))))\n",
    "    msk = msk == 1.\n",
    "    np.random.shuffle(msk)\n",
    "    \n",
    "    indices_true = np.where(msk)[0]\n",
    "    indices_false = np.where(~msk)[0]\n",
    "\n",
    "    train = feature_matrix[indices_true,:]\n",
    "    train_target = target[msk]\n",
    "    test = feature_matrix[indices_false,:]\n",
    "    test_target = target[~msk]\n",
    "    \n",
    "    return train, train_target, test, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_next_data(train, train_target, feature_matrix, target, y_pred, n):\n",
    "    diff = np.absolute(y_pred - 0.5)\n",
    "    sorted_ids = np.argsort(diff)\n",
    "        \n",
    "    plt.hist(diff)\n",
    "    plt.show()\n",
    "    \n",
    "    for i in range(n):\n",
    "        train = sparse.vstack((train, feature_matrix[sorted_ids[i]]))\n",
    "        train_target = np.append(train_target, [target[sorted_ids[i]]])\n",
    "        \n",
    "    print train.shape\n",
    "        \n",
    "    return train, train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_file = \"/tmp/test.csv\"\n",
    "output_file = \"/tmp/rules.csv\"\n",
    "number_rules = 200\n",
    "\n",
    "dirty.to_csv(input_file,header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"rule_features4\", \"rb\") as f:\n",
    "    rule_decision = pickle.load(f)\n",
    "    f.close\n",
    "\n",
    "with open(\"rule_names4\", \"rb\") as g:\n",
    "    rules_names = pickle.load(g)\n",
    "    f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_matrix_all = sparse.hstack((feature_matrix,rule_decision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix_all = feature_matrix_all.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1131672, 208)\n"
     ]
    }
   ],
   "source": [
    "#feature_matrix_all = feature_matrix\n",
    "print feature_matrix_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_schema_all = []\n",
    "total_schema_all.extend(schema_metadata)\n",
    "total_schema_all.extend(rules_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for nn in range(len(total_schema_all)):\n",
    "    total_schema_all[nn] = str(nn) + \"_\" + total_schema_all[nn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0_col_id', '1_col_distinct_values', '2_col_avg_length', '3_col_max_length', '4_val_fraction', '5_val_length', '6_row_avg_fraction', '7_row_avg_length', '8_I=> ', '9_7=> ', '10_3=> ', '11_2=> ', '12_1=> ', '13_0=> ', '14_ =>A', '15_ =>E', '16_ =>R', '17_ =>D', '18_4=> ', '19_ =>S', '20_A=> ', '21_5=> ', '22_ =>e', '23_ =>a', '24_ =>T', '25_ =>r', '26_E=> ', '27_6=> ', '28_a=> ', '29_ =>t', '30_ =>N', '31_e=> ', '32_R=> ', '33_ =>L', '34_N=> ', '35_ =>I', '36_ =>O', '37_T=> ', '38_ =>AE', '39_ =>n', '40_S=> ', '41_ =>AR', '42_ =>ER', '43_r=> ', '44_8=> ', '45_t=> ', '46_1=> A', '47_1=>A', '48_n=> ', '49_ 1=>A', '50_9=> ', '51_O=> ', '52_ =>er', '53_12=> ', '54_ =>o', '55_ =>C', '56_01=> ', '57_ =>i', '58_1=> R', '59_L=> ', '60_1=>0', '61_ =>DR', '62_1=>R', '63_ 1=>R', '64_o=> ', '65_ =>ae', '66_ =>AT', '67_ =>d', '68_ =>l', '69_ =>AN', '70_ =>ar', '71_1=>E', '72_1=> 0', '73_ =>ET', '74_1=> E', '75_ =>RT', '76_D=> ', '77_l=> ', '78_1=>T', '79_i=> ', '80_ =>s', '81_1=>S', '82_ 1=>E', '83_1=> S', '84_ 1=>S', '85_A=>E', '86_ =>ST', '87_1A=> ', '88_ =>et', '89_ A=>E', '90_ =>EN', '91_1=>e', '92_E=>R', '93_ E=>R', '94_ =>AD', '95_AE=> ', '96_1=> e', '97_ =>NR', '98_ =>AS', '99_ 1=>e', '100_1=>2', '101_2=>A', '102_ 1=>T', '103_1=> T', '104_E=> R', '105_2=> A', '106_ 2=>A', '107_1=>r', '108_S=>T', '109_ =>rt', '110_ S=>T', '111_1=> r', '112_ =>AL', '113_1=>t', '114_A=>R', '115_0=>A', '116_13=> ', '117_ =>en', '118_0=> A', '119_ 1=>r', '120_ 0=>A', '121_1=> 2', '122_ =>ES', '123_ A=>R', '124_ =>at', '125_AR=> ', '126_ =>an', '127_ =>OR', '128_A=> R', '129_ER=> ', '130_ =>DE', '131_ =>V', '132_1=>a', '133_1E=> ', '134_1=> t', '135_1=> a', '136_ 1=>t', '137_ e=>r', '138_e=>r', '139_ 1=>a', '140_ =>RS', '141_ =>H', '142_C=> ', '143_2=>R', '144_1=>D', '145_14=> ', '146_ =>W', '147_15=> ', '148_ =>EL', '149_1=>N', '150_ 1=>D', '151_1=> D', '152_ =>AER', '153_ =>NT', '154_e=> r', '155_A=>T', '156_1=> N', '157_ =>nr', '158_ A=>T', '159_ 1=>N', '160_E=>A', '161_ =>AO', '162_2=> R', '163_A=> T', '164_ 2=>R', '165_ a=>e', '166_a=>e', '167_er=> ', '168_1e=> ', '169_AN=> ', '170_ E=>A', '171_ =>LR', '172_s=> ', '173_ae=> ', '174_a=>r', '175_ =>IR', '176_ a=>r', '177_ =>AI', '178_0=>R', '179_ =>P', '180_02=> ', '181_E=> A', '182_A=> E', '183_ E=>T', '184_E=>T', '185_a=> r', '186_ 0=>R', '187_0=> R', '188_R=>A', '189_ =>or', '190_2=>E', '191_ R=>A', '192_2=> E', '193_ =>dr', '194_H=> ', '195_R=>D', '196_1R=> ', '197_ =>v', '198_ 2=>E', '199_1a=> ', '200_ R=>D', '201_E=> T', '202_AT=> ', '203_ =>nt', '204_R=>E', '205_ =>EO', '206_ar=> ', '207_ R=>E']\n"
     ]
    }
   ],
   "source": [
    "print total_schema_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[      4      16      28 ..., 1131640 1131652 1131664]\n"
     ]
    }
   ],
   "source": [
    "ff = feature_matrix_all[:,0]\n",
    "row, col, data = sparse.find(ff == 4)\n",
    "print row\n",
    "#print address_id\n",
    "feature_matrix_all_address = feature_matrix_all[row,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix_all_save = feature_matrix_all\n",
    "feature_matrix_all = feature_matrix_all_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_save = target\n",
    "target = target[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<94306x208 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 4534363 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix_all_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_size = 1000\n",
    "\n",
    "our_params = {'eta': 0.1, 'seed': 0, 'subsample': 0.8, 'colsample_bytree': 0.8,\n",
    "                          'objective': 'binary:logistic', 'max_depth': 3, 'min_child_weight': 1}\n",
    "\n",
    "\n",
    "train, train_target, test, test_target = create_data(feature_matrix_all, train_size)\n",
    "xgdmat = xgb.DMatrix(train, train_target, feature_names=total_schema_all)\n",
    "\n",
    "cv_params = {'max_depth': [3,5,7], 'min_child_weight': [1,3,5]}\n",
    "ind_params = {'max_depth': 3, 'learning_rate': 0.1, 'n_estimators': 1000, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "     'objective': 'binary:logistic'}\n",
    "\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                    cv_params, \n",
    "                     scoring = 'f1', cv = 5, n_jobs = 4) \n",
    "\n",
    "optimized_GBM.fit(train, train_target)\n",
    "\n",
    "print \"best scores: \" + str(optimized_GBM.grid_scores_)\n",
    "\n",
    "our_params = optimized_GBM.best_params_\n",
    "\n",
    "print \"train size: \" + str(train_size) + \"best params: \" + str(our_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1207)\n",
      "0.0\n",
      "{'116_a=>r': 12, '0_col_id': 1093, '611_F=>L': 1, '921_a=> ': 3, '467_ =>l': 2, '357_O=>S': 8, '359_l=>a': 5, '823_P=> O': 8, '316_e=>r': 4, '423_ =>T': 12, '352_e=>a': 2, '315_a=>e': 1, '511_A=>N': 1, '556_T=>O': 7, '717_ =>3': 3, '810_O=> ': 8, '945_,=> A': 2, '320_r=>e': 5, '720_A=> ': 1, '410_2=> ': 1, '1008_0=>-': 7, '716_ =>2': 1, '408_7=> ': 1, '943_O=> ': 4, '576_C=>A': 11, '413_ =>A': 15, '318_a=>r': 15, '915_A=> ': 22, '123_A=>L': 6, '813_P=> ': 1, '373_S=>A': 2, '1031_1=>-': 1, '380_A=>T': 3, '453_ =>o': 3, '818_o=> ': 7, '338_a=>l': 3, '363_T=>E': 9, '377_M=>E': 1, '5_val_length': 2036, '510_O=>N': 20, '508_A=>O': 1, '323_L=>E': 13, '420_5=> ': 1, '819_B=>O': 2, '349_L=>A': 4, '309_R=>A': 4, '955_T=> ': 1, '130_e=>r': 5, '428_ =>t': 10, '828_O=>X': 1, '120_a=>e': 9, '482_A=>E': 1, '933_A=> ,': 7, '332_R=>O': 2, '313_a=>n': 1, '215_a=>n': 1, '321_o=>n': 13, '977_,o=> ': 1, '415_ =>R': 23, '821_ =>3': 1, '1007_5=>0': 1, '1_col_distinct_values': 840, '346_R=>I': 6, '6_row_avg_fraction': 4923, '1021_0=>2': 1, '4_val_fraction': 3748, '310_A=>E': 2, '324_E=>N': 8, '418_ =>S': 1, '314_R=>E': 1, '174_S=>E': 4, '443_8=> ': 1, '1001_AO=> ': 5, '913_,=> ': 1, '824_P=>O': 2, '382_M=>N': 1, '1090_5=>9': 1, '319_O=>N': 3, '544_N=>T': 1, '551_C=>O': 13, '411_1=> ': 7, '925_,a=> ': 1, '811_ =>B': 2, '612_C=>A': 1, '112_A=>N': 19, '421_ =>e': 6, '436_T=> ': 2, '712_ =>9': 11, '412_0=> ': 1, '910_ =>7': 2, '409_3=> ': 3, '439_S=> ': 1, '732_2=>0': 1, '312_A=>N': 11, '718_ =>0': 4, '425_E=> ': 1, '414_ =>E': 18, '356_R=>S': 1, '419_A=> ': 6, '2_col_avg_length': 610, '110_A=>E': 11, '347_e=>s': 4, '980_R=> ': 1, '424_ =>r': 6, '3_col_max_length': 458, '483_ =>ST': 1, '195_R=>L': 2, '117_i=>a': 2, '438_ =>n': 4, '512_a=>n': 5, '730_3=>0': 1, '434_ =>I': 3, '1004_,AO=> ': 1, '7_row_avg_length': 3061, '721_ =>7': 4}\n",
      "(1000, 1207)\n",
      "0.84134528336\n",
      "{'131_r=>e': 9, '116_a=>r': 6, '122_R=>I': 6, '0_col_id': 1049, '611_F=>L': 1, '921_a=> ': 2, '467_ =>l': 3, '359_l=>a': 1, '138_E=>L': 1, '316_e=>r': 1, '423_ =>T': 17, '193_n=>i': 5, '490_ E=>R': 1, '556_T=>O': 12, '717_ =>3': 12, '810_O=> ': 10, '419_A=> ': 11, '163_O=>E': 4, '334_n=>e': 4, '555_E=>R': 3, '320_r=>e': 12, '410_2=> ': 8, '1008_0=>-': 6, '519_L=>E': 1, '111_A=>R': 4, '114_I=>A': 10, '135_L=>A': 6, '119_R=>E': 3, '429_ =>N': 1, '716_ =>2': 1, '526_R=>O': 3, '943_O=> ': 9, '513_A=>E': 4, '171_J=>E': 2, '915_A=> ': 5, '614_c=>a': 1, '1031_1=>-': 5, '144_l=>a': 5, '724_7=>0': 1, '118_A=>I': 2, '180_d=>a': 6, '155_D=>A': 4, '338_a=>l': 9, '363_T=>E': 3, '5_val_length': 2168, '510_O=>N': 1, '349_L=>A': 6, '919_,=> 3': 1, '808_ =>0': 1, '130_e=>r': 4, '428_ =>t': 9, '534_A=>I': 3, '381_E=>L': 13, '153_I=>N': 2, '313_a=>n': 12, '984_,=> 6': 1, '321_o=>n': 2, '140_e=>n': 2, '415_ =>R': 14, '821_ =>3': 2, '1_col_distinct_values': 939, '346_R=>I': 2, '6_row_avg_fraction': 5316, '709_ =>1': 2, '4_val_fraction': 3546, '523_l=>e': 1, '310_A=>E': 3, '1017_1=>6': 1, '324_E=>N': 3, '418_ =>S': 2, '712_ =>9': 12, '907_ =>6': 1, '413_ =>A': 7, '525_I=>E': 5, '416_ =>D': 2, '911_ =>2': 1, '389_I=>L': 2, '125_i=>e': 2, '411_1=> ': 15, '148_n=>e': 2, '328_R=>N': 6, '409_3=> ': 3, '421_ =>e': 4, '314_R=>E': 6, '1023_0=>6': 2, '112_A=>N': 8, '516_a=>e': 1, '368_M=>A': 6, '145_E=>I': 6, '591_M=>A': 9, '807_ =>4': 1, '312_A=>N': 5, '718_ =>0': 5, '425_E=> ': 3, '1026_0=>5': 1, '414_ =>E': 25, '713_9=>5': 1, '547_N=>E': 9, '2_col_avg_length': 673, '736_7=>5': 9, '311_E=>R': 6, '440_ =>AR': 1, '818_o=> ': 6, '322_A=>S': 9, '424_ =>r': 8, '452_12=> ': 1, '3_col_max_length': 560, '563_S=>O': 13, '814_ =>1': 1, '7_row_avg_length': 2870, '721_ =>7': 3}\n",
      "(1000, 1207)\n",
      "1.66993546356\n",
      "{'122_R=>I': 2, '0_col_id': 997, '921_a=> ': 7, '912_ =>9': 1, '823_P=> O': 1, '326_r=>a': 2, '316_e=>r': 9, '160_r=>o': 5, '423_ =>T': 5, '511_A=>N': 12, '139_n=>a': 4, '556_T=>O': 9, '717_ =>3': 3, '810_O=> ': 10, '820_ =>5': 1, '317_A=>R': 1, '320_r=>e': 4, '410_2=> ': 1, '1008_0=>-': 6, '111_A=>R': 10, '518_a=>l': 3, '114_I=>A': 1, '429_ =>N': 12, '716_ =>2': 4, '943_O=> ': 4, '455_01=> ': 1, '348_i=>e': 3, '341_I=>A': 11, '125_i=>e': 3, '413_ =>A': 19, '318_a=>r': 2, '915_A=> ': 16, '1031_1=>-': 7, '144_l=>a': 1, '453_ =>o': 1, '432_ =>L': 1, '338_a=>l': 1, '465_ =>AT': 2, '5_val_length': 1997, '510_O=>N': 6, '309_R=>A': 4, '428_ =>t': 6, '441_ =>ER': 1, '354_r=>i': 4, '427_a=> ': 1, '332_R=>O': 4, '520_L=>A': 2, '313_a=>n': 4, '415_ =>R': 20, '537_r=>e': 1, '1_col_distinct_values': 816, '6_row_avg_fraction': 4789, '1021_0=>2': 1, '4_val_fraction': 3429, '621_A=>R': 1, '927_L=> ': 1, '310_A=>E': 9, '324_E=>N': 1, '314_R=>E': 9, '416_ =>D': 7, '554_S=>T': 1, '911_ =>2': 2, '319_O=>N': 11, '1022_0=>8': 1, '126_a=>i': 1, '411_1=> ': 7, '982_e=> ': 1, '328_R=>N': 1, '612_C=>A': 2, '112_A=>N': 8, '421_ =>e': 8, '436_T=> ': 2, '712_ =>9': 15, '121_r=>a': 9, '13_A=>9': 1, '412_0=> ': 6, '917_,A=> ': 1, '368_M=>A': 1, '591_M=>A': 12, '430_e=> ': 2, '113_a=>n': 5, '718_ =>0': 4, '414_ =>E': 10, '115_R=>A': 5, '987_n=> ': 1, '713_9=>5': 1, '366_r=>s': 1, '419_A=> ': 2, '1025_0=>7': 1, '2_col_avg_length': 640, '311_E=>R': 6, '110_A=>E': 2, '1024_0=>4': 1, '818_o=> ': 8, '424_ =>r': 5, '422_ =>a': 9, '3_col_max_length': 475, '530_N=>O': 8, '117_i=>a': 13, '438_ =>n': 1, '814_ =>1': 2, '512_a=>n': 5, '120_a=>e': 5, '910_ =>7': 2, '926_ =>A': 3, '951_ =>1': 1, '434_ =>I': 5, '7_row_avg_length': 2785, '721_ =>7': 3}\n",
      "(1000, 1207)\n",
      "2.49168537947\n",
      "{'116_a=>r': 3, '426_6=> ': 1, '0_col_id': 1033, '921_a=> ': 12, '151_o=>n': 5, '942_E=> ': 1, '823_P=> O': 2, '460_ =>DR': 5, '917_,A=> ': 1, '316_e=>r': 1, '822_BO=> ': 4, '423_ =>T': 15, '812_B=> ': 1, '556_T=>O': 5, '717_ =>3': 1, '810_O=> ': 24, '507_A=>D': 11, '919_,=> 3': 1, '419_A=> ': 3, '317_A=>R': 7, '163_O=>E': 10, '320_r=>e': 3, '410_2=> ': 12, '1008_0=>-': 4, '519_L=>E': 15, '111_A=>R': 18, '143_e=>l': 1, '937_,L=> ': 2, '337_i=>n': 4, '135_L=>A': 2, '119_R=>E': 4, '429_ =>N': 7, '408_7=> ': 1, '146_O=>N': 2, '348_i=>e': 4, '341_I=>A': 5, '413_ =>A': 20, '384_n=>a': 3, '318_a=>r': 4, '915_A=> ': 4, '1031_1=>-': 8, '380_A=>T': 8, '453_ =>o': 1, '118_A=>I': 3, '347_e=>s': 2, '359_l=>a': 1, '1074_7=>3': 1, '114_I=>A': 17, '557_I=>N': 11, '363_T=>E': 7, '5_val_length': 2342, '510_O=>N': 4, '349_L=>A': 11, '819_B=>O': 6, '158_e=>i': 1, '361_S=>O': 4, '432_ =>L': 12, '959_,E=> ': 2, '428_ =>t': 6, '564_L=>N': 1, '397_a=>t': 1, '120_a=>e': 5, '534_A=>I': 22, '315_a=>e': 9, '415_ =>R': 17, '475_1=>T': 1, '124_E=>R': 1, '1_col_distinct_values': 945, '6_row_avg_fraction': 5234, '333_l=>e': 4, '183_O=>R': 1, '4_val_fraction': 3262, '825_OP=> ': 1, '927_L=> ': 10, '412_0=> ': 6, '827_o=>x': 2, '539_O=>R': 1, '722_C=> ': 2, '913_,=> ': 1, '824_P=>O': 2, '466_ =>d': 1, '142_e=>a': 5, '319_O=>N': 6, '514_S=>N': 2, '402_e=>z': 1, '411_1=> ': 3, '112_A=>N': 13, '731_ =>4': 2, '815_BP=> ': 1, '421_ =>e': 6, '436_T=> ': 5, '712_ =>9': 7, '121_r=>a': 1, '1023_0=>6': 1, '910_ =>7': 1, '409_3=> ': 2, '430_e=> ': 6, '113_a=>n': 5, '312_A=>N': 16, '718_ =>0': 4, '414_ =>E': 14, '1020_0=>9': 1, '547_N=>E': 1, '2_col_avg_length': 695, '152_L=>I': 1, '400_l=>n': 3, '435_ =>O': 7, '737_ =>6': 1, '818_o=> ': 13, '980_R=> ': 3, '928_C=>9': 1, '424_ =>r': 6, '422_ =>a': 7, '3_col_max_length': 446, '117_i=>a': 1, '829_B=> O': 1, '438_ =>n': 8, '512_a=>n': 4, '405_e=>o': 4, '434_ =>I': 8, '923_,=> 7': 1, '311_E=>R': 8, '7_row_avg_length': 3141, '721_ =>7': 6}\n",
      "(1000, 1207)\n",
      "3.3397289185\n",
      "{'131_r=>e': 5, '116_a=>r': 6, '426_6=> ': 3, '0_col_id': 1011, '921_a=> ': 5, '357_O=>S': 6, '912_ =>9': 1, '326_r=>a': 2, '822_BO=> ': 1, '423_ =>T': 1, '315_a=>e': 6, '511_A=>N': 8, '752_5=>0': 1, '710_9=>1': 1, '826_ =>O': 1, '812_B=> ': 1, '717_ =>3': 3, '810_O=> ': 26, '419_A=> ': 11, '317_A=>R': 5, '163_O=>E': 4, '555_E=>R': 7, '410_2=> ': 1, '1008_0=>-': 7, '111_A=>R': 1, '114_I=>A': 11, '1013_1=>9': 1, '401_n=>o': 1, '918_ =>3': 1, '716_ =>2': 5, '559_A=>T': 9, '341_I=>A': 10, '413_ =>A': 15, '521_R=>E': 21, '915_A=> ': 19, '581_R=>I': 1, '133_N=>E': 15, '1031_1=>-': 5, '528_A=>R': 16, '134_M=>A': 1, '196_o=>r': 6, '347_e=>s': 3, '432_ =>L': 6, '338_a=>l': 6, '5_val_length': 1953, '510_O=>N': 6, '508_A=>O': 5, '349_L=>A': 2, '323_L=>E': 4, '309_R=>A': 1, '422_ =>a': 3, '428_ =>t': 4, '442_r=> ': 4, '427_a=> ': 2, '534_A=>I': 2, '215_a=>n': 1, '321_o=>n': 2, '140_e=>n': 10, '415_ =>R': 7, '1_col_distinct_values': 930, '6_row_avg_fraction': 5442, '1021_0=>2': 1, '4_val_fraction': 3686, '345_A=>O': 2, '708_ =>5': 1, '324_E=>N': 5, '418_ =>S': 9, '174_S=>E': 4, '827_o=>x': 1, '525_I=>E': 2, '911_ =>2': 1, '319_O=>N': 11, '411_1=> ': 2, '925_,a=> ': 1, '917_,A=> ': 2, '421_ =>e': 16, '712_ =>9': 11, '121_r=>a': 4, '112_A=>N': 12, '439_S=> ': 1, '145_E=>I': 3, '312_A=>N': 7, '1041_2=>3': 1, '414_ =>E': 18, '115_R=>A': 15, '1020_0=>9': 1, '547_N=>E': 11, '2_col_avg_length': 682, '311_E=>R': 18, '1024_0=>4': 2, '818_o=> ': 12, '322_A=>S': 1, '424_ =>r': 4, '1105_5=>6': 1, '3_col_max_length': 508, '530_N=>O': 5, '814_ =>1': 3, '512_a=>n': 6, '721_ =>7': 5, '1084_1=>89': 1, '353_S=>N': 1, '1018_1=>8': 2, '7_row_avg_length': 2844, '327_e=>n': 10}\n",
      "F-Score: [0.83667658046720095]\n",
      "Precision: [0.81942789141258776]\n",
      "Recall: [0.85522254394874186]\n"
     ]
    }
   ],
   "source": [
    "f_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "models = dict()\n",
    "\n",
    "n = 5\n",
    "for train_size in [1000]:\n",
    "    f_current = 0.0\n",
    "    precision_current = 0.0\n",
    "    recall_current = 0.0\n",
    "    \n",
    "    our_params = {'eta': 0.1, 'seed': 0, 'subsample': 0.8, 'colsample_bytree': 0.8,\n",
    "                          'objective': 'binary:logistic', 'max_depth': 5, 'min_child_weight': 1}\n",
    "\n",
    "    for t in range(n):\n",
    "        train, train_target, test, test_target = create_data(feature_matrix_all, train_size)\n",
    "        \n",
    "        print train.shape\n",
    "        \n",
    "        xgdmat = xgb.DMatrix(train, train_target, feature_names=total_schema_all)\n",
    " \n",
    "        final_gb = xgb.train(our_params, xgdmat, num_boost_round=3000)\n",
    "\n",
    "        testdmat = xgb.DMatrix(feature_matrix_all, feature_names=total_schema_all)\n",
    "        y_pred = final_gb.predict(testdmat)\n",
    "\n",
    "        res = (y_pred > 0.5)\n",
    "\n",
    "        print f1_score(target, res)\n",
    "        f_current += f1_score(target, res)\n",
    "        precision_current += precision_score(target, res)\n",
    "        recall_current += recall_score(target, res)\n",
    "        \n",
    "        print final_gb.get_fscore()\n",
    "    \n",
    "    f_scores.append(f_current / n)\n",
    "    precision_scores.append(precision_current / n)\n",
    "    recall_scores.append(recall_current / n)\n",
    "\n",
    "print \"F-Score: \" + str(f_scores)\n",
    "print \"Precision: \" + str(precision_scores)\n",
    "print \"Recall: \" + str(recall_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0_col_id',\n",
       " '1_col_distinct_values',\n",
       " '2_col_avg_length',\n",
       " '3_col_max_length',\n",
       " '4_val_fraction',\n",
       " '5_val_length',\n",
       " '6_row_avg_fraction',\n",
       " '7_row_avg_length',\n",
       " '8_9=>47',\n",
       " '9_9=>78',\n",
       " '10_9=>4',\n",
       " '11_9=>6',\n",
       " '12_A=>79',\n",
       " '13_A=>9',\n",
       " '14_A=>89',\n",
       " '15_9=>7',\n",
       " '16_9=>8',\n",
       " '17_A=>69',\n",
       " '18_9=>5',\n",
       " '19_A=>59',\n",
       " '20_A=>49',\n",
       " '21_9=>3',\n",
       " '22_A=>39',\n",
       " '23_A=>19',\n",
       " '24_A=>29',\n",
       " '25_9=>1',\n",
       " '26_A=>09',\n",
       " '27_9=>2',\n",
       " '28_9=>0',\n",
       " '29_A=>789',\n",
       " '30_9=>57',\n",
       " '31_9=>67',\n",
       " '32_A=>679',\n",
       " '33_A=>689',\n",
       " '34_9=>68',\n",
       " '35_A=>589',\n",
       " '36_A=>579',\n",
       " '37_9=>56',\n",
       " '38_9=>58',\n",
       " '39_A=>569',\n",
       " '40_A=>489',\n",
       " '41_A=>479',\n",
       " '42_9=>48',\n",
       " '43_9=>14',\n",
       " '44_9=>16',\n",
       " '45_A=>179',\n",
       " '46_9=>45',\n",
       " '47_9=>46',\n",
       " '48_A=>469',\n",
       " '49_A=>459',\n",
       " '50_A=>289',\n",
       " '51_A=>189',\n",
       " '52_A=>389',\n",
       " '53_A=>279',\n",
       " '54_9=>17',\n",
       " '55_9=>18',\n",
       " '56_9=>37',\n",
       " '57_A=>379',\n",
       " '58_9=>38',\n",
       " '59_9=>27',\n",
       " '60_A=>169',\n",
       " '61_A=>369',\n",
       " '62_9=>28',\n",
       " '63_A=>269',\n",
       " '64_A=>159',\n",
       " '65_A=>359',\n",
       " '66_A=>259',\n",
       " '67_9=>15',\n",
       " '68_9=>35',\n",
       " '69_9=>36',\n",
       " '70_9=>26',\n",
       " '71_A=>149',\n",
       " '72_9=>25',\n",
       " '73_A=>349',\n",
       " '74_A=>249',\n",
       " '75_9=>24',\n",
       " '76_9=>07',\n",
       " '77_9=>13',\n",
       " '78_A=>129',\n",
       " '79_9=>34',\n",
       " '80_A=>239',\n",
       " '81_9=>12',\n",
       " '82_A=>139',\n",
       " '83_A=>089',\n",
       " '84_9=>23',\n",
       " '85_A=>079',\n",
       " '86_9=>08',\n",
       " '87_9=>02',\n",
       " '88_9=>04',\n",
       " '89_9=>05',\n",
       " '90_9=>06',\n",
       " '91_A=>069',\n",
       " '92_A=>059',\n",
       " '93_A=>049',\n",
       " '94_9=>01',\n",
       " '95_A=>029',\n",
       " '96_A=>039',\n",
       " '97_A=>019',\n",
       " '98_9=>03',\n",
       " '99_8A=>9',\n",
       " '100_89=>5',\n",
       " '101_7A=>3',\n",
       " '102_7A=>5',\n",
       " '103_7A=>9',\n",
       " '104_7A=>1',\n",
       " '105_79=>3',\n",
       " '106_79=>1',\n",
       " '107_79=>5',\n",
       " '108_H=>A',\n",
       " '109_E=>A',\n",
       " '110_A=>E',\n",
       " '111_A=>R',\n",
       " '112_A=>N',\n",
       " '113_a=>n',\n",
       " '114_I=>A',\n",
       " '115_R=>A',\n",
       " '116_a=>r',\n",
       " '117_i=>a',\n",
       " '118_A=>I',\n",
       " '119_R=>E',\n",
       " '120_a=>e',\n",
       " '121_r=>a',\n",
       " '122_R=>I',\n",
       " '123_A=>L',\n",
       " '124_E=>R',\n",
       " '125_i=>e',\n",
       " '126_a=>i',\n",
       " '127_I=>E',\n",
       " '128_r=>i',\n",
       " '129_N=>A',\n",
       " '130_e=>r',\n",
       " '131_r=>e',\n",
       " '132_L=>E',\n",
       " '133_N=>E',\n",
       " '134_M=>A',\n",
       " '135_L=>A',\n",
       " '136_E=>N',\n",
       " '137_a=>l',\n",
       " '138_E=>L',\n",
       " '139_n=>a',\n",
       " '140_e=>n',\n",
       " '141_R=>N',\n",
       " '142_e=>a',\n",
       " '143_e=>l',\n",
       " '144_l=>a',\n",
       " '145_E=>I',\n",
       " '146_O=>N',\n",
       " '147_R=>O',\n",
       " '148_n=>e',\n",
       " '149_i=>n',\n",
       " '150_r=>n',\n",
       " '151_o=>n',\n",
       " '152_L=>I',\n",
       " '153_I=>N',\n",
       " '154_A=>D',\n",
       " '155_D=>A',\n",
       " '156_C=>A',\n",
       " '157_S=>A',\n",
       " '158_e=>i',\n",
       " '159_l=>i',\n",
       " '160_r=>o',\n",
       " '161_l=>e',\n",
       " '162_M=>I',\n",
       " '163_O=>E',\n",
       " '164_o=>e',\n",
       " '165_M=>E',\n",
       " '166_A=>O',\n",
       " '167_H=>E',\n",
       " '168_C=>E',\n",
       " '169_O=>A',\n",
       " '170_a=>d',\n",
       " '171_J=>E',\n",
       " '172_T=>A',\n",
       " '173_N=>I',\n",
       " '174_S=>E',\n",
       " '175_R=>AI',\n",
       " '176_I=>L',\n",
       " '177_A=>EL',\n",
       " '178_h=>a',\n",
       " '179_M=>R',\n",
       " '180_d=>a',\n",
       " '181_i=>l',\n",
       " '182_A=>EN',\n",
       " '183_O=>R',\n",
       " '184_o=>a',\n",
       " '185_I=>C',\n",
       " '186_c=>a',\n",
       " '187_L=>N',\n",
       " '188_m=>a',\n",
       " '189_h=>e',\n",
       " '190_A=>T',\n",
       " '191_IR=>A',\n",
       " '192_s=>a',\n",
       " '193_n=>i',\n",
       " '194_r=>ai',\n",
       " '195_R=>L',\n",
       " '196_o=>r',\n",
       " '197_i=>c',\n",
       " '198_AR=>I',\n",
       " '199_R=>Y',\n",
       " '200_AR=>N',\n",
       " '201_a=>o',\n",
       " '202_IL=>A',\n",
       " '203_s=>e',\n",
       " '204_a=>el',\n",
       " '205_ar=>i',\n",
       " '206_l=>n',\n",
       " '207_E=>T',\n",
       " '208_E=>L',\n",
       " '209_A=>D',\n",
       " '210_W=>N',\n",
       " '211_A=>R',\n",
       " '212_A=>E',\n",
       " '213_a=>e',\n",
       " '214_A=>N',\n",
       " '215_a=>n',\n",
       " '216_E=>R',\n",
       " '217_A=>L',\n",
       " '218_N=>E',\n",
       " '219_n=>e',\n",
       " '220_e=>r',\n",
       " '221_a=>r',\n",
       " '222_L=>N',\n",
       " '223_a=>l',\n",
       " '224_R=>E',\n",
       " '225_a=>en',\n",
       " '226_an=>e',\n",
       " '227_E=>N',\n",
       " '228_R=>O',\n",
       " '229_r=>e',\n",
       " '230_W=>A',\n",
       " '231_l=>n',\n",
       " '232_R=>N',\n",
       " '233_A=>EN',\n",
       " '234_a=>y',\n",
       " '235_AN=>E',\n",
       " '236_r=>o',\n",
       " '237_A=>Y',\n",
       " '238_e=>n',\n",
       " '239_l=>a',\n",
       " '240_A=>LN',\n",
       " '241_E=>O',\n",
       " '242_L=>O',\n",
       " '243_a=>ey',\n",
       " '244_L=>E',\n",
       " '245_L=>A',\n",
       " '246_D=>E',\n",
       " '247_o=>n',\n",
       " '248_y=>n',\n",
       " '249_W=>E',\n",
       " '250_r=>n',\n",
       " '251_A=>EY',\n",
       " '252_a=>eny',\n",
       " '253_AW=>N',\n",
       " '254_O=>N',\n",
       " '255_AL=>N',\n",
       " '256_y=>e',\n",
       " '257_W=>AN',\n",
       " '258_W=>EN',\n",
       " '259_ay=>n',\n",
       " '260_AW=>E',\n",
       " '261_W=>AE',\n",
       " '262_B=>R',\n",
       " '263_A=>O',\n",
       " '264_e=>o',\n",
       " '265_Y=>E',\n",
       " '266_Y=>N',\n",
       " '267_ny=>e',\n",
       " '268_any=>e',\n",
       " '269_l=>o',\n",
       " '270_ay=>en',\n",
       " '271_e=>l',\n",
       " '272_y=>en',\n",
       " '273_E=>T',\n",
       " '274_l=>e',\n",
       " '275_R=>D',\n",
       " '276_W=>AEN',\n",
       " '277_AW=>EN',\n",
       " '278_A=>ENY',\n",
       " '279_AY=>N',\n",
       " '280_al=>n',\n",
       " '281_ANW=>E',\n",
       " '282_u=>e',\n",
       " '283_R=>A',\n",
       " '284_ANY=>E',\n",
       " '285_AY=>EN',\n",
       " '286_WY=>EN',\n",
       " '287_AW=>ENY',\n",
       " '288_NY=>E',\n",
       " '289_NW=>E',\n",
       " '290_r=>t',\n",
       " '291_Y=>EN',\n",
       " '292_W=>AENY',\n",
       " '293_R=>I',\n",
       " '294_I=>N',\n",
       " '295_i=>e',\n",
       " '296_a=>o',\n",
       " '297_R=>T',\n",
       " '298_r=>i',\n",
       " '299_e=>t',\n",
       " '300_E=>OR',\n",
       " '301_a=>d',\n",
       " '302_ER=>O',\n",
       " '303_AE=>R',\n",
       " '304_a=>ln',\n",
       " '305_L=>AN',\n",
       " '306_L=>R',\n",
       " '307_A=>D',\n",
       " '308_E=>A',\n",
       " '309_R=>A',\n",
       " '310_A=>E',\n",
       " '311_E=>R',\n",
       " '312_A=>N',\n",
       " '313_a=>n',\n",
       " '314_R=>E',\n",
       " '315_a=>e',\n",
       " '316_e=>r',\n",
       " '317_A=>R',\n",
       " '318_a=>r',\n",
       " '319_O=>N',\n",
       " '320_r=>e',\n",
       " '321_o=>n',\n",
       " '322_A=>S',\n",
       " '323_L=>E',\n",
       " '324_E=>N',\n",
       " '325_N=>E',\n",
       " '326_r=>a',\n",
       " '327_e=>n',\n",
       " '328_R=>N',\n",
       " '329_a=>s',\n",
       " '330_A=>L',\n",
       " '331_O=>E',\n",
       " '332_R=>O',\n",
       " '333_l=>e',\n",
       " '334_n=>e',\n",
       " '335_I=>N',\n",
       " '336_r=>n',\n",
       " '337_i=>n',\n",
       " '338_a=>l',\n",
       " '339_E=>S',\n",
       " '340_o=>e',\n",
       " '341_I=>A',\n",
       " '342_O=>R',\n",
       " '343_A=>I',\n",
       " '344_I=>E',\n",
       " '345_A=>O',\n",
       " '346_R=>I',\n",
       " '347_e=>s',\n",
       " '348_i=>e',\n",
       " '349_L=>A',\n",
       " '350_a=>o',\n",
       " '351_r=>o',\n",
       " '352_e=>a',\n",
       " '353_S=>N',\n",
       " '354_r=>i',\n",
       " '355_a=>i',\n",
       " '356_R=>S',\n",
       " '357_O=>S',\n",
       " '358_o=>r',\n",
       " '359_l=>a',\n",
       " '360_o=>s',\n",
       " '361_S=>O',\n",
       " '362_I=>S',\n",
       " '363_T=>E',\n",
       " '364_i=>s',\n",
       " '365_i=>a',\n",
       " '366_r=>s',\n",
       " '367_C=>A',\n",
       " '368_M=>A',\n",
       " '369_L=>O',\n",
       " '370_N=>A',\n",
       " '371_S=>E',\n",
       " '372_s=>n',\n",
       " '373_S=>A',\n",
       " '374_H=>A',\n",
       " '375_O=>A',\n",
       " '376_t=>e',\n",
       " '377_M=>E',\n",
       " '378_L=>N',\n",
       " '379_A=>ER',\n",
       " '380_A=>T',\n",
       " '381_E=>L',\n",
       " '382_M=>N',\n",
       " '383_D=>E',\n",
       " '384_n=>a',\n",
       " '385_H=>E',\n",
       " '386_C=>E',\n",
       " '387_E=>Z',\n",
       " '388_o=>a',\n",
       " '389_I=>L',\n",
       " '390_s=>o',\n",
       " '391_E=>O',\n",
       " '392_a=>d',\n",
       " '393_e=>l',\n",
       " '394_N=>O',\n",
       " '395_AR=>N',\n",
       " '396_i=>l',\n",
       " '397_a=>t',\n",
       " '398_l=>o',\n",
       " '399_N=>S',\n",
       " '400_l=>n',\n",
       " '401_n=>o',\n",
       " '402_e=>z',\n",
       " '403_AR=>E',\n",
       " '404_a=>er',\n",
       " '405_e=>o',\n",
       " '406_A=>EN',\n",
       " '407_I=> ',\n",
       " '408_7=> ',\n",
       " '409_3=> ',\n",
       " '410_2=> ',\n",
       " '411_1=> ',\n",
       " '412_0=> ',\n",
       " '413_ =>A',\n",
       " '414_ =>E',\n",
       " '415_ =>R',\n",
       " '416_ =>D',\n",
       " '417_4=> ',\n",
       " '418_ =>S',\n",
       " '419_A=> ',\n",
       " '420_5=> ',\n",
       " '421_ =>e',\n",
       " '422_ =>a',\n",
       " '423_ =>T',\n",
       " '424_ =>r',\n",
       " '425_E=> ',\n",
       " '426_6=> ',\n",
       " '427_a=> ',\n",
       " '428_ =>t',\n",
       " '429_ =>N',\n",
       " '430_e=> ',\n",
       " '431_R=> ',\n",
       " '432_ =>L',\n",
       " '433_N=> ',\n",
       " '434_ =>I',\n",
       " '435_ =>O',\n",
       " '436_T=> ',\n",
       " '437_ =>AE',\n",
       " '438_ =>n',\n",
       " '439_S=> ',\n",
       " '440_ =>AR',\n",
       " '441_ =>ER',\n",
       " '442_r=> ',\n",
       " '443_8=> ',\n",
       " '444_t=> ',\n",
       " '445_1=> A',\n",
       " '446_1=>A',\n",
       " '447_n=> ',\n",
       " '448_ 1=>A',\n",
       " '449_9=> ',\n",
       " '450_O=> ',\n",
       " '451_ =>er',\n",
       " '452_12=> ',\n",
       " '453_ =>o',\n",
       " '454_ =>C',\n",
       " '455_01=> ',\n",
       " '456_ =>i',\n",
       " '457_1=> R',\n",
       " '458_L=> ',\n",
       " '459_1=>0',\n",
       " '460_ =>DR',\n",
       " '461_1=>R',\n",
       " '462_ 1=>R',\n",
       " '463_o=> ',\n",
       " '464_ =>ae',\n",
       " '465_ =>AT',\n",
       " '466_ =>d',\n",
       " '467_ =>l',\n",
       " '468_ =>AN',\n",
       " '469_ =>ar',\n",
       " '470_1=>E',\n",
       " '471_1=> 0',\n",
       " '472_ =>ET',\n",
       " '473_1=> E',\n",
       " '474_ =>RT',\n",
       " '475_1=>T',\n",
       " '476_i=> ',\n",
       " '477_ =>s',\n",
       " '478_1=>S',\n",
       " '479_ 1=>E',\n",
       " '480_1=> S',\n",
       " '481_ 1=>S',\n",
       " '482_A=>E',\n",
       " '483_ =>ST',\n",
       " '484_1A=> ',\n",
       " '485_ =>et',\n",
       " '486_ A=>E',\n",
       " '487_ =>EN',\n",
       " '488_1=>e',\n",
       " '489_E=>R',\n",
       " '490_ E=>R',\n",
       " '491_ =>AD',\n",
       " '492_AE=> ',\n",
       " '493_1=> e',\n",
       " '494_ =>NR',\n",
       " '495_ =>AS',\n",
       " '496_ 1=>e',\n",
       " '497_1=>2',\n",
       " '498_2=>A',\n",
       " '499_ 1=>T',\n",
       " '500_1=> T',\n",
       " '501_E=> R',\n",
       " '502_2=> A',\n",
       " '503_ 2=>A',\n",
       " '504_S=>T',\n",
       " '505_ =>rt',\n",
       " '506_ S=>T',\n",
       " '507_A=>D',\n",
       " '508_A=>O',\n",
       " '509_A=>L',\n",
       " '510_O=>N',\n",
       " '511_A=>N',\n",
       " '512_a=>n',\n",
       " '513_A=>E',\n",
       " '514_S=>N',\n",
       " '515_o=>n',\n",
       " '516_a=>e',\n",
       " '517_S=>A',\n",
       " '518_a=>l',\n",
       " '519_L=>E',\n",
       " '520_L=>A',\n",
       " '521_R=>E',\n",
       " '522_l=>a',\n",
       " '523_l=>e',\n",
       " '524_R=>N',\n",
       " '525_I=>E',\n",
       " '526_R=>O',\n",
       " '527_O=>A',\n",
       " '528_A=>R',\n",
       " '529_R=>A',\n",
       " '530_N=>O',\n",
       " '531_i=>e',\n",
       " '532_r=>n',\n",
       " '533_s=>n',\n",
       " '534_A=>I',\n",
       " '535_a=>o',\n",
       " '536_n=>o',\n",
       " '537_r=>e',\n",
       " '538_AS=>N',\n",
       " '539_O=>R',\n",
       " '540_E=>N',\n",
       " '541_O=>T',\n",
       " '542_a=>i',\n",
       " '543_r=>o',\n",
       " '544_N=>T',\n",
       " '545_a=>r',\n",
       " '546_r=>a',\n",
       " '547_N=>E',\n",
       " '548_e=>n',\n",
       " '549_o=>t',\n",
       " '550_n=>t',\n",
       " '551_C=>O',\n",
       " '552_N=>A',\n",
       " '553_L=>O',\n",
       " '554_S=>T',\n",
       " '555_E=>R',\n",
       " '556_T=>O',\n",
       " '557_I=>N',\n",
       " '558_S=>E',\n",
       " '559_A=>T',\n",
       " '560_e=>r',\n",
       " '561_o=>r',\n",
       " '562_S=>AN',\n",
       " '563_S=>O',\n",
       " '564_L=>N',\n",
       " '565_t=>o',\n",
       " '566_n=>a',\n",
       " '567_n=>e',\n",
       " '568_a=>d',\n",
       " '569_i=>n',\n",
       " '570_A=>S',\n",
       " '571_E=>A',\n",
       " '572_E=>O',\n",
       " '573_E=>L',\n",
       " '574_R=>T',\n",
       " '575_a=>t',\n",
       " '576_C=>A',\n",
       " '577_S=>I',\n",
       " '578_l=>n',\n",
       " '579_r=>t',\n",
       " '580_T=>A',\n",
       " '581_R=>I',\n",
       " '582_s=>o',\n",
       " '583_I=>L',\n",
       " '584_e=>a',\n",
       " '585_O=>E',\n",
       " '586_e=>o',\n",
       " '587_AL=>E',\n",
       " '588_i=>l',\n",
       " '589_o=>a',\n",
       " '590_s=>e',\n",
       " '591_M=>A',\n",
       " '592_A=>NO',\n",
       " '593_l=>o',\n",
       " '594_T=>N',\n",
       " '595_E=>T',\n",
       " '596_E=>S',\n",
       " '597_c=>o',\n",
       " '598_O=>L',\n",
       " '599_s=>t',\n",
       " '600_e=>s',\n",
       " '601_s=>a',\n",
       " '602_a=>s',\n",
       " '603_a=>no',\n",
       " '604_e=>l',\n",
       " '605_r=>i',\n",
       " '606_e=>t',\n",
       " '607_A=>E',\n",
       " '608_R=>A',\n",
       " '609_A=>I',\n",
       " '610_A=>L',\n",
       " '611_F=>L',\n",
       " '612_C=>A',\n",
       " '613_C=>a',\n",
       " '614_c=>a',\n",
       " '615_T=>X',\n",
       " '616_A=>N',\n",
       " '617_a=>l',\n",
       " '618_L=>I',\n",
       " '619_C=>I',\n",
       " '620_l=>i',\n",
       " '621_A=>R',\n",
       " '622_a=>i',\n",
       " '623_F=>A',\n",
       " '624_C=>L',\n",
       " '625_L=>A',\n",
       " '626_r=>a',\n",
       " '627_A=>S',\n",
       " '628_E=>S',\n",
       " '629_a=>n',\n",
       " '630_e=>s',\n",
       " '631_F=>l',\n",
       " '632_a=>s',\n",
       " '633_l=>a',\n",
       " '634_C=>AL',\n",
       " '635_a=>r',\n",
       " '636_f=>l',\n",
       " '637_O=>R',\n",
       " '638_AC=>L',\n",
       " '639_o=>r',\n",
       " '640_AC=>I',\n",
       " '641_A=>IL',\n",
       " '642_O=>A',\n",
       " '643_E=>A',\n",
       " '644_A=>O',\n",
       " '645_al=>i',\n",
       " '646_R=>I',\n",
       " '647_C=>AI',\n",
       " '648_a=>il',\n",
       " '649_o=>a',\n",
       " '650_r=>i',\n",
       " '651_AL=>I',\n",
       " '652_i=>a',\n",
       " '653_C=>IL',\n",
       " '654_CL=>I',\n",
       " '655_C=>AIL',\n",
       " '656_e=>a',\n",
       " '657_ACL=>I',\n",
       " '658_AC=>IL',\n",
       " '659_I=>A',\n",
       " '660_a=>o',\n",
       " '661_FL=>A',\n",
       " '662_T=>x',\n",
       " '663_t=>x',\n",
       " '664_T=>E',\n",
       " '665_O=>I',\n",
       " '666_R=>N',\n",
       " '667_I=>O',\n",
       " '668_AE=>S',\n",
       " '669_L=>O',\n",
       " '670_i=>o',\n",
       " '671_F=>.',\n",
       " '672_l=>o',\n",
       " '673_o=>i',\n",
       " '674_r=>n',\n",
       " '675_OR=>A',\n",
       " '676_or=>a',\n",
       " '677_R=>AI',\n",
       " '678_A=>NO',\n",
       " '679_r=>ai',\n",
       " '680_O=>N',\n",
       " '681_l=>f',\n",
       " '682_F=>R',\n",
       " '683_L=>R',\n",
       " '684_o=>n',\n",
       " '685_i=>n',\n",
       " '686_o=>ar',\n",
       " '687_I=>N',\n",
       " '688_O=>AR',\n",
       " '689_l=>r',\n",
       " '690_c=>i',\n",
       " '691_ae=>s',\n",
       " '692_F=>O',\n",
       " '693_a=>e',\n",
       " '694_C=>O',\n",
       " '695_ir=>a',\n",
       " '696_a=>f',\n",
       " '697_IL=>A',\n",
       " '698_il=>a',\n",
       " '699_L=>AR',\n",
       " '700_F=>OR',\n",
       " '701_A=>.',\n",
       " '702_a=>no',\n",
       " '703_LR=>A',\n",
       " '704_l=>ar',\n",
       " '705_lr=>a',\n",
       " '706_f=>a',\n",
       " '707_3=>5',\n",
       " '708_ =>5',\n",
       " '709_ =>1',\n",
       " '710_9=>1',\n",
       " '711_9=>0',\n",
       " '712_ =>9',\n",
       " '713_9=>5',\n",
       " '714_9=>2',\n",
       " '715_9=>3',\n",
       " '716_ =>2',\n",
       " '717_ =>3',\n",
       " '718_ =>0',\n",
       " '719_3=>2',\n",
       " '720_A=> ',\n",
       " '721_ =>7',\n",
       " '722_C=> ',\n",
       " '723_9=>4',\n",
       " '724_7=>0',\n",
       " '725_9=>6',\n",
       " '726_3=>4',\n",
       " '727_ C=>9',\n",
       " '728_C=>9',\n",
       " '729_C=> 9',\n",
       " '730_3=>0',\n",
       " '731_ =>4',\n",
       " '732_2=>0',\n",
       " '733_3=>1',\n",
       " '734_a=> ',\n",
       " '735_7=>2',\n",
       " '736_7=>5',\n",
       " '737_ =>6',\n",
       " '738_3=>6',\n",
       " '739_ =>09',\n",
       " '740_7=>6',\n",
       " '741_9=>7',\n",
       " '742_7=>1',\n",
       " '743_3=>7',\n",
       " '744_ =>29',\n",
       " '745_ 9=>0',\n",
       " '746_A=>9',\n",
       " '747_ A=>9',\n",
       " '748_ =>19',\n",
       " '749_a=>9',\n",
       " '750_A=> 9',\n",
       " '751_ =>8',\n",
       " '752_5=>0',\n",
       " '753_F=> ',\n",
       " '754_C=>A',\n",
       " '755_ 9=>1',\n",
       " '756_ a=>9',\n",
       " '757_a=> 9',\n",
       " '758_AC=> ',\n",
       " '759_ =>39',\n",
       " '760_C=> A',\n",
       " '761_ AC=>9',\n",
       " '762_2=>1',\n",
       " '763_ 9=>2',\n",
       " '764_AC=>9',\n",
       " '765_C=>9A',\n",
       " '766_2=>5',\n",
       " '767_C=> 9A',\n",
       " '768_AC=> 9',\n",
       " '769_9=>8',\n",
       " '770_9=>02',\n",
       " '771_2=>7',\n",
       " '772_7=>8',\n",
       " '773_2=>3',\n",
       " '774_9=>25',\n",
       " '775_7=>4',\n",
       " '776_9=>35',\n",
       " '777_3=>9',\n",
       " '778_F=>3',\n",
       " '779_F=> 3',\n",
       " '780_ F=>3',\n",
       " '781_ =>59',\n",
       " '782_L=> ',\n",
       " '783_7=>3',\n",
       " '784_2=>4',\n",
       " '785_C=>1',\n",
       " '786_C=>0',\n",
       " '787_5=>3',\n",
       " '788_l=> ',\n",
       " '789_ 9=>5',\n",
       " '790_2=>6',\n",
       " '791_ =>49',\n",
       " '792_3=>8',\n",
       " '793_9=>01',\n",
       " '794_2=>8',\n",
       " '795_9=>05',\n",
       " '796_C=> 0',\n",
       " '797_ C=>0',\n",
       " '798_ =>79',\n",
       " '799_C=>09',\n",
       " '800_29=>0',\n",
       " '801_9C=>0',\n",
       " '802_ C=>09',\n",
       " '803_5=>6',\n",
       " '804_ 9C=>0',\n",
       " '805_C=> 09',\n",
       " '806_ C=>1',\n",
       " '807_ =>4',\n",
       " '808_ =>0',\n",
       " '809_ =>2',\n",
       " '810_O=> ',\n",
       " '811_ =>B',\n",
       " '812_B=> ',\n",
       " '813_P=> ',\n",
       " '814_ =>1',\n",
       " '815_BP=> ',\n",
       " '816_P=> B',\n",
       " '817_ P=>B',\n",
       " '818_o=> ',\n",
       " '819_B=>O',\n",
       " '820_ =>5',\n",
       " '821_ =>3',\n",
       " '822_BO=> ',\n",
       " '823_P=> O',\n",
       " '824_P=>O',\n",
       " '825_OP=> ',\n",
       " '826_ =>O',\n",
       " '827_o=>x',\n",
       " '828_O=>X',\n",
       " '829_B=> O',\n",
       " '830_O=> X',\n",
       " '831_o=> x',\n",
       " '832_X=> ',\n",
       " '833_OX=> ',\n",
       " '834_ =>o',\n",
       " '835_B=> X',\n",
       " '836_x=> ',\n",
       " '837_B=>X',\n",
       " '838_BO=>X',\n",
       " '839_BX=> ',\n",
       " '840_ox=> ',\n",
       " '841_BOX=> ',\n",
       " '842_B=>OX',\n",
       " '843_BO=> X',\n",
       " '844_ =>6',\n",
       " '845_B=> OX',\n",
       " '846_ O=>B',\n",
       " '847_ =>X',\n",
       " '848_ =>BO',\n",
       " '849_O=> B',\n",
       " '850_ =>x',\n",
       " '851_ O=>X',\n",
       " '852_ P=>O',\n",
       " '853_ o=>x',\n",
       " '854_ =>OX',\n",
       " '855_ B=>O',\n",
       " '856_ =>ox',\n",
       " '857_ =>BX',\n",
       " '858_ B=>X',\n",
       " '859_ BO=>X',\n",
       " '860_ =>BOX',\n",
       " '861_ B=>OX',\n",
       " '862_BP=>X',\n",
       " '863_PX=> ',\n",
       " '864_P=> X',\n",
       " '865_B=>1',\n",
       " '866_P=> BO',\n",
       " '867_O=> BX',\n",
       " '868_BOP=> ',\n",
       " '869_ O=>BX',\n",
       " '870_ B=>1',\n",
       " '871_OP=> B',\n",
       " '872_OP=> X',\n",
       " '873_P=> OX',\n",
       " '874_B=> 1',\n",
       " '875_ P=>BO',\n",
       " '876_ OP=>B',\n",
       " '877_ P=>1',\n",
       " '878_P=>1',\n",
       " '879_OPX=> ',\n",
       " '880_ P=>X',\n",
       " '881_BP=>O',\n",
       " '882_ OP=>X',\n",
       " '883_BOP=>X',\n",
       " '884_P=> 1',\n",
       " '885_BP=>OX',\n",
       " '886_BPX=> ',\n",
       " '887_ P=>OX',\n",
       " '888_BP=> O',\n",
       " '889_P=> BOX',\n",
       " '890_ BP=>O',\n",
       " '891_BP=> X',\n",
       " '892_BOP=> X',\n",
       " '893_BP=> OX',\n",
       " '894_ BP=>X',\n",
       " '895_ BOP=>X',\n",
       " '896_ P=>BX',\n",
       " '897_OP=> BX',\n",
       " '898_O=>1',\n",
       " '899_ BP=>OX',\n",
       " '900_ P=>BOX',\n",
       " '901_ =>1B',\n",
       " '902_ OP=>BX',\n",
       " '903_O=> 1',\n",
       " '904_ O=>1',\n",
       " '905_ =>7',\n",
       " '906_ =>8',\n",
       " '907_ =>6',\n",
       " '908_ =>0',\n",
       " '909_ =>,',\n",
       " '910_ =>7',\n",
       " '911_ =>2',\n",
       " '912_ =>9',\n",
       " '913_,=> ',\n",
       " '914_,=> 9',\n",
       " '915_A=> ',\n",
       " '916_,=> 2',\n",
       " '917_,A=> ',\n",
       " '918_ =>3',\n",
       " '919_,=> 3',\n",
       " '920_ =>C',\n",
       " '921_a=> ',\n",
       " '922_C=> ',\n",
       " '923_,=> 7',\n",
       " '924_,C=> ',\n",
       " '925_,a=> ',\n",
       " '926_ =>A',\n",
       " '927_L=> ',\n",
       " '928_C=>9',\n",
       " '929_,=> 5',\n",
       " '930_ =>5',\n",
       " '931_,C=> 9',\n",
       " '932_C=> 9',\n",
       " '933_A=> ,',\n",
       " '934_,C=>9',\n",
       " '935_ =>9C',\n",
       " '936_,=> C',\n",
       " '937_,L=> ',\n",
       " '938_,=> 9C',\n",
       " '939_ ,=>C',\n",
       " '940_ =>4',\n",
       " '941_ ,=>9C',\n",
       " '942_E=> ',\n",
       " '943_O=> ',\n",
       " '944_ =>a',\n",
       " '945_,=> A',\n",
       " '946_,=> 0',\n",
       " '947_,=> 4',\n",
       " '948_a=> ,',\n",
       " '949_ ,=>A',\n",
       " '950_l=> ',\n",
       " '951_ =>1',\n",
       " '952_,O=> ',\n",
       " '953_,l=> ',\n",
       " '954_,=> 1',\n",
       " '955_T=> ',\n",
       " '956_,A=> 9',\n",
       " '957_A=>9',\n",
       " '958_N=> ',\n",
       " '959_,E=> ',\n",
       " '960_,A=>9',\n",
       " '961_A=> 9',\n",
       " '962_,N=> ',\n",
       " '963_AL=> ',\n",
       " '964_AC=> ',\n",
       " '965_O=> ,',\n",
       " '966_,AC=> ',\n",
       " '967_,AL=> ',\n",
       " '968_,=> 29',\n",
       " '969_,=> a',\n",
       " '970_ =>29',\n",
       " '971_N=> ,',\n",
       " '972_,T=> ',\n",
       " '973_E=> ,',\n",
       " '974_o=> ',\n",
       " '975_ ,=>a',\n",
       " '976_S=> ',\n",
       " '977_,o=> ',\n",
       " '978_,a=>9',\n",
       " '979_F=> ',\n",
       " '980_R=> ',\n",
       " '981_,S=> ',\n",
       " '982_e=> ',\n",
       " '983_ =>9A',\n",
       " '984_,=> 6',\n",
       " '985_,e=> ',\n",
       " '986_,R=> ',\n",
       " '987_n=> ',\n",
       " '988_,n=> ',\n",
       " '989_a=>9',\n",
       " '990_S=> ,',\n",
       " '991_,F=> ',\n",
       " '992_al=> ',\n",
       " '993_,al=> ',\n",
       " '994_a=> 9',\n",
       " '995_AN=> ',\n",
       " '996_,AN=> ',\n",
       " '997_,a=> 9',\n",
       " '998_ =>,9',\n",
       " '999_o=> ,',\n",
       " ...]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_gb.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0_col_id': 1070,\n",
       " '1008_0=>-': 12,\n",
       " '1014_1=>3': 1,\n",
       " '1020_0=>9': 1,\n",
       " '1023_0=>6': 1,\n",
       " '1031_1=>-': 5,\n",
       " '1032_9=>1': 1,\n",
       " '1062_1=>27': 1,\n",
       " '108_H=>A': 5,\n",
       " '109_E=>A': 7,\n",
       " '110_A=>E': 12,\n",
       " '112_A=>N': 8,\n",
       " '115_R=>A': 6,\n",
       " '130_e=>r': 14,\n",
       " '134_M=>A': 1,\n",
       " '140_e=>n': 4,\n",
       " '1_col_distinct_values': 1048,\n",
       " '2_col_avg_length': 628,\n",
       " '309_R=>A': 10,\n",
       " '311_E=>R': 11,\n",
       " '313_a=>n': 8,\n",
       " '314_R=>E': 4,\n",
       " '315_a=>e': 1,\n",
       " '317_A=>R': 5,\n",
       " '318_a=>r': 7,\n",
       " '320_r=>e': 1,\n",
       " '323_L=>E': 9,\n",
       " '327_e=>n': 9,\n",
       " '330_A=>L': 1,\n",
       " '339_E=>S': 3,\n",
       " '347_e=>s': 3,\n",
       " '366_r=>s': 4,\n",
       " '367_C=>A': 3,\n",
       " '369_L=>O': 1,\n",
       " '3_col_max_length': 462,\n",
       " '407_I=> ': 1,\n",
       " '411_1=> ': 12,\n",
       " '412_0=> ': 1,\n",
       " '413_ =>A': 10,\n",
       " '414_ =>E': 17,\n",
       " '415_ =>R': 9,\n",
       " '416_ =>D': 1,\n",
       " '418_ =>S': 2,\n",
       " '419_A=> ': 5,\n",
       " '421_ =>e': 8,\n",
       " '422_ =>a': 4,\n",
       " '423_ =>T': 7,\n",
       " '424_ =>r': 2,\n",
       " '428_ =>t': 7,\n",
       " '429_ =>N': 2,\n",
       " '434_ =>I': 2,\n",
       " '435_ =>O': 3,\n",
       " '450_O=> ': 1,\n",
       " '465_ =>AT': 1,\n",
       " '4_val_fraction': 3583,\n",
       " '508_A=>O': 10,\n",
       " '509_A=>L': 4,\n",
       " '511_A=>N': 2,\n",
       " '512_a=>n': 3,\n",
       " '519_L=>E': 8,\n",
       " '524_R=>N': 3,\n",
       " '525_I=>E': 4,\n",
       " '526_R=>O': 6,\n",
       " '527_O=>A': 5,\n",
       " '539_O=>R': 6,\n",
       " '540_E=>N': 1,\n",
       " '552_N=>A': 7,\n",
       " '560_e=>r': 8,\n",
       " '569_i=>n': 9,\n",
       " '572_E=>O': 2,\n",
       " '595_E=>T': 7,\n",
       " '5_val_length': 1919,\n",
       " '612_C=>A': 1,\n",
       " '614_c=>a': 2,\n",
       " '631_F=>l': 1,\n",
       " '6_row_avg_fraction': 5062,\n",
       " '709_ =>1': 1,\n",
       " '712_ =>9': 13,\n",
       " '715_9=>3': 3,\n",
       " '716_ =>2': 9,\n",
       " '717_ =>3': 6,\n",
       " '718_ =>0': 5,\n",
       " '721_ =>7': 2,\n",
       " '724_7=>0': 1,\n",
       " '725_9=>6': 1,\n",
       " '736_7=>5': 1,\n",
       " '775_7=>4': 1,\n",
       " '7_row_avg_length': 3130,\n",
       " '810_O=> ': 5,\n",
       " '812_B=> ': 1,\n",
       " '813_P=> ': 3,\n",
       " '818_o=> ': 5,\n",
       " '819_B=>O': 1,\n",
       " '823_P=> O': 12,\n",
       " '824_P=>O': 1,\n",
       " '826_ =>O': 1,\n",
       " '831_o=> x': 1,\n",
       " '910_ =>7': 1,\n",
       " '912_ =>9': 1,\n",
       " '913_,=> ': 1,\n",
       " '915_A=> ': 8,\n",
       " '917_,A=> ': 2,\n",
       " '921_a=> ': 7,\n",
       " '922_C=> ': 1,\n",
       " '923_,=> 7': 1,\n",
       " '924_,C=> ': 1,\n",
       " '943_O=> ': 5,\n",
       " '952_,O=> ': 1,\n",
       " '955_T=> ': 1,\n",
       " '958_N=> ': 1,\n",
       " '965_O=> ,': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = final_gb.get_fscore()\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 10best params: {'colsample_bytree': 0.8, 'min_child_weight': 1, 'subsample': 0.8, 'eta': 0.1, 'objective': 'binary:logistic', 'seed': 0, 'max_depth': 5}\n",
      "1 - F-Score: 0.634506541305\n",
      "1 - Precision: 0.49816062648\n",
      "1 - Recall: 0.873613388124\n",
      "(20, 208)\n",
      "2 - F-Score: 0.897858395643\n",
      "2 - Precision: 0.980074061012\n",
      "2 - Recall: 0.828368854728\n",
      "(30, 208)\n",
      "2 - F-Score: 0.870252139718\n",
      "2 - Precision: 0.952599194794\n",
      "2 - Recall: 0.801009219239\n",
      "(40, 208)\n",
      "2 - F-Score: 0.893657758277\n",
      "2 - Precision: 0.840470429351\n",
      "2 - Recall: 0.95403155407\n",
      "(50, 208)\n",
      "2 - F-Score: 0.955989154128\n",
      "2 - Precision: 0.954862143676\n",
      "2 - Recall: 0.957118828113\n",
      "(60, 208)\n",
      "2 - F-Score: 0.962529857721\n",
      "2 - Precision: 0.939541390426\n",
      "2 - Recall: 0.98667149275\n",
      "(70, 208)\n",
      "2 - F-Score: 0.954685253026\n",
      "2 - Precision: 0.941511387164\n",
      "2 - Recall: 0.96823301467\n",
      "(80, 208)\n",
      "2 - F-Score: 0.972304554291\n",
      "2 - Precision: 0.970273937749\n",
      "2 - Recall: 0.974343688121\n",
      "(90, 208)\n",
      "2 - F-Score: 0.989162204254\n",
      "2 - Precision: 0.991149874944\n",
      "2 - Recall: 0.987182489833\n",
      "(100, 208)\n",
      "2 - F-Score: 0.989181031734\n",
      "2 - Precision: 0.987501856685\n",
      "2 - Recall: 0.99086592714\n",
      "F-Score: [0.98918103173422323]\n",
      "Precision: [0.98750185668512747]\n",
      "Recall: [0.99086592714033261]\n"
     ]
    }
   ],
   "source": [
    "#active learning\n",
    "\n",
    "f_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "models = dict()\n",
    "\n",
    "n = 1\n",
    "for train_size in [10]:\n",
    "    f_current = 0.0\n",
    "    precision_current = 0.0\n",
    "    recall_current = 0.0\n",
    "    \n",
    "    our_params = {'eta': 0.1, 'seed': 0, 'subsample': 0.8, 'colsample_bytree': 0.8,\n",
    "                          'objective': 'binary:logistic', 'max_depth': 5, 'min_child_weight': 1}\n",
    "\n",
    "    print \"train size: \" + str(train_size) + \"best params: \" + str(our_params)\n",
    "    \n",
    "    for t in range(n):\n",
    "        train, train_target, test, test_target = create_data(feature_matrix_all, train_size)\n",
    "        \n",
    "        xgdmat = xgb.DMatrix(train, train_target, feature_names=total_schema_all)\n",
    " \n",
    "        final_gb = xgb.train(our_params, xgdmat, num_boost_round=3000)\n",
    "\n",
    "        testdmat = xgb.DMatrix(feature_matrix_all, feature_names=total_schema_all)\n",
    "        y_pred = final_gb.predict(testdmat)\n",
    "\n",
    "        res = (y_pred > 0.5)\n",
    "                \n",
    "        print \"1 - F-Score: \" + str(f1_score(target, res))\n",
    "        print \"1 - Precision: \" + str(precision_score(target, res))\n",
    "        print \"1 - Recall: \" + str(recall_score(target, res))\n",
    "        \n",
    "        \n",
    "        for r in range (9):\n",
    "            train, train_target = create_next_data(train, train_target,feature_matrix_all, target, y_pred, 10)\n",
    "\n",
    "            xgdmat2 = xgb.DMatrix(train, train_target, feature_names=total_schema_all)\n",
    "\n",
    "            final_gb2 = xgb.train(our_params, xgdmat2, num_boost_round=3000)\n",
    "\n",
    "            y_pred = final_gb2.predict(testdmat)\n",
    "\n",
    "            res2 = (y_pred > 0.5)\n",
    "\n",
    "            print \"2 - F-Score: \" + str(f1_score(target, res2))\n",
    "            print \"2 - Precision: \" + str(precision_score(target, res2))\n",
    "            print \"2 - Recall: \" + str(recall_score(target, res2))\n",
    "                \n",
    "        f_current += f1_score(target, res2)\n",
    "        precision_current += precision_score(target, res2)\n",
    "        recall_current += recall_score(target, res2)\n",
    "    \n",
    "    f_scores.append(f_current / n)\n",
    "    precision_scores.append(precision_current / n)\n",
    "    recall_scores.append(recall_current / n)\n",
    "\n",
    "print \"F-Score: \" + str(f_scores)\n",
    "print \"Precision: \" + str(precision_scores)\n",
    "print \"Recall: \" + str(recall_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-316a533aaa74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'matplotlib inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimportance_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Importance'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Feature'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mimportance_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Importance'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimportance_frame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'barh'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Feature'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'orange'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "importance_frame = pd.DataFrame({'Importance': list(importances.values()), 'Feature': list(importances.keys())})\n",
    "importance_frame.sort_values(by = 'Importance', inplace = True)\n",
    "importance_frame[0:40].plot(kind = 'barh', x = 'Feature', figsize = (8,8), color = 'orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_gb2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-93e2294980f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimportances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_gb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_fscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msorted_imp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0msorted_imp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_gb2' is not defined"
     ]
    }
   ],
   "source": [
    "importances = final_gb2.get_fscore()\n",
    "\n",
    "import operator\n",
    "sorted_imp = sorted(importances.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print sorted_imp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score: [0.1890476877457227, 0.37834691631269701, 0.58013839104177711, 0.64066265622150431, 0.76637150886752126, 0.88541243966779748, 0.8904424312141298, 0.89418077951191766, 0.89400388396576158]\n",
      "Precision: [0.12948940111400137, 0.62960554503886479, 0.70424754442742199, 0.64042826713778922, 0.807455474301358, 0.90216814718046978, 0.89283842140448699, 0.89833355466123843, 0.89884032575999573]\n",
      "Recall: [0.35217309570185013, 0.34439729061364038, 0.55682396832813552, 0.65127321356131895, 0.75088111053690398, 0.86981633402841962, 0.88823521575000952, 0.89007312570900476, 0.88922014444919262]\n"
     ]
    }
   ],
   "source": [
    "f_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "n = 5\n",
    "for train_size in [2, 5, 10, 15, 100, 1000, 10000, 100000, 200000]:\n",
    "    f_current = 0.0\n",
    "    precision_current = 0.0\n",
    "    recall_current = 0.0\n",
    "    for t in range(n):\n",
    "        train, train_target, test, test_target = create_data(feature_matrix, train_size)\n",
    "\n",
    "        gnb = GaussianNB()\n",
    "        final = gnb.fit(train, train_target)\n",
    "\n",
    "        res = final.predict(test)\n",
    "        \n",
    "        f_current += f1_score(test_target, res)\n",
    "        precision_current += precision_score(test_target, res)\n",
    "        recall_current += recall_score(test_target, res)\n",
    "    \n",
    "    f_scores.append(f_current / n)\n",
    "    precision_scores.append(precision_current / n)\n",
    "    recall_scores.append(recall_current / n)\n",
    "\n",
    "print \"F-Score: \" + str(f_scores)\n",
    "print \"Precision: \" + str(precision_scores)\n",
    "print \"Recall: \" + str(recall_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score: [0.87223511722492031, 0.89280466393892388, 0.9687255651065676, 0.95227522685165267, 0.95391058569075116, 0.95623387247360725]\n",
      "Precision: [0.93076489020254838, 0.90334381529741548, 0.99457415845025388, 0.9703945073953697, 0.97138393496406006, 0.97921391826144721]\n",
      "Recall: [0.84483747697020684, 0.88643684568142933, 0.94420199829901663, 0.93495260626051502, 0.93739386301633743, 0.93440290289820849]\n"
     ]
    }
   ],
   "source": [
    "f_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "n = 5\n",
    "for train_size in [30,100,1000,10000,30000,100000]:\n",
    "    f_current = 0.0\n",
    "    precision_current = 0.0\n",
    "    recall_current = 0.0\n",
    "    \n",
    "    for t in range(n):\n",
    "        train, train_target, test, test_target = create_data(feature_matrix, train_size)\n",
    "\n",
    "        logistic = linear_model.LogisticRegression()\n",
    "        final = logistic.fit(train, train_target)\n",
    "\n",
    "        res = final.predict(test)\n",
    "        \n",
    "        f_current += f1_score(test_target, res)\n",
    "        precision_current += precision_score(test_target, res)\n",
    "        recall_current += recall_score(test_target, res)\n",
    "    \n",
    "    f_scores.append(f_current / n)\n",
    "    precision_scores.append(precision_current / n)\n",
    "    recall_scores.append(recall_current / n)\n",
    "\n",
    "print \"F-Score: \" + str(f_scores)\n",
    "print \"Precision: \" + str(precision_scores)\n",
    "print \"Recall: \" + str(recall_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.931965062081\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(test_target, res)\n",
    "print \"recall: \" + str(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.963111878677\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(test_target, res)\n",
    "print \"precision: \" + str(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_detect = np.array([False] * len(clean) * len(clean.columns))\n",
    "target = np.array([False] * len(clean) * len(clean.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for row in range(len(clean)):\n",
    "    for column in range(len(clean.columns)):\n",
    "        column_detect[i] = (row, column) in error_sets[4]\n",
    "        target[i] = ground_truth[row,column]\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TP = np.sum(np.logical_and(column_detect == True, target == True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FP = np.sum(np.logical_and(column_detect == True, target == False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FN = np.sum(np.logical_and(column_detect == False, target == True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.999349493101\n"
     ]
    }
   ],
   "source": [
    "print \"precision: \" + str(float(TP) / (TP + FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.946619217082\n"
     ]
    }
   ],
   "source": [
    "print \"recall: \" + str(float(TP) / (TP + FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
