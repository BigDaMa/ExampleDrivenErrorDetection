import numpy as np
from plotlatex_lib import plot_list_latex
from plotlatex_lib import plot_list
from plotlatex_lib import plot_integral
from plotlatex_lib import plot_end
from plotlatex_lib import plot_integral_latex
from plotlatex_lib import plot_outperform
from plotlatex_lib import plot_outperform_latex

labels_optimum = [4, 8, 12, 16, 20, 24, 28, 38, 48, 58, 68, 78, 88, 98, 108, 118, 128, 138, 148, 158, 168]


totaluncertainty_sim = []
totaluncertainty_sim.append([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14240343779747952, 0.57419650110247011, 0.65224792138728371, 0.77541722633542742, 0.86576406419439189, 0.94823968944421855, 0.97039178410575777, 0.97069260656383971, 0.97711460257065386, 0.97765858750056667, 0.98141598670602159])
average_totaluncertainty_sim = list(np.mean(np.matrix(totaluncertainty_sim), axis=0).A1)

maxchangeprediction_sim = []
maxchangeprediction_sim.append([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14240343779747952, 0.57419650110247011, 0.65224792138728371, 0.77541722633542742, 0.77603544848892558, 0.78865501250079606, 0.86257381702858749, 0.86642212391805751, 0.91919034346250894, 0.94458916770302426, 0.95468473955845534])
average_maxchangeprediction_sim = list(np.mean(np.matrix(maxchangeprediction_sim), axis=0).A1)

roundrobin_sim = []
roundrobin_sim.append([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14240343779747952, 0.57419650110247011, 0.65224792138728371, 0.77541722633542742, 0.77541722633542742, 0.77541722633542742, 0.77541813204758803, 0.87133822970657104, 0.87094122876664781, 0.94726269342993774, 0.94726269342993774])
average_roundrobin_sim = list(np.mean(np.matrix(roundrobin_sim), axis=0).A1)

labels_maxuncertainty_sim = [4, 8, 12, 16, 20, 24, 28, 38, 48, 58, 68, 78, 88, 98, 108, 118, 128, 138, 148, 158, 168]
maxuncertainty_sim = []
maxuncertainty_sim.append([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14240343779747952, 0.57419650110247011, 0.65224792138728371, 0.77541722633542742, 0.83485354681199464, 0.92015835231987109, 0.9467868300437523, 0.95570151038474227, 0.96990069512787414, 0.97467869985639555, 0.97624950299666458])
average_maxuncertainty_sim = list(np.mean(np.matrix(maxuncertainty_sim), axis=0).A1)

random_sim = []
random_sim.append([0.0, 0.02391893104583993, 0.068520634965112598, 0.10400306983103792, 0.17857639367922432, 0.2481910945837319, 0.29992436859834193, 0.36416121055971773, 0.39645716696293343, 0.45692581103219132, 0.50976605145855636, 0.56185336037779121, 0.61292375129374033, 0.65169908398471177, 0.68871347976335928, 0.70951576206330957, 0.73001748959954682, 0.7559461126146424, 0.77196782934982511, 0.79565354956631074, 0.81088573674100117])
average_random_sim = list(np.mean(np.matrix(random_sim), axis=0).A1)

mincross_sim = []
mincross_sim.append([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14240343779747952, 0.57419650110247011, 0.65224792138728371, 0.77541722633542742, 0.77541722633542742, 0.77539962895994896, 0.77540067036830296, 0.77540284793662129, 0.7754050585699892, 0.77540670310462756, 0.77540847422715053])
average_mincross_sim = list(np.mean(np.matrix(mincross_sim), axis=0).A1)

max_false_pred_sim = []
max_false_pred_sim.append([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14240343779747952, 0.57419650110247011, 0.65224792138728371, 0.77541722633542742, 0.84291522457334778, 0.92776157244266666, 0.95570151038474227, 0.96009884959862968, 0.96383665172483113, 0.96481820187417533, 0.96590959577821833])
average_max_false_pred_sim = list(np.mean(np.matrix(max_false_pred_sim), axis=0).A1)

max_fimpact_pred_sim = []
max_fimpact_pred_sim.append([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14240343779747952, 0.57419650110247011, 0.65224792138728371, 0.77541722633542742, 0.86331655878896962, 0.93921045402886705, 0.97047740707366947, 0.97468382407568277, 0.97180306002861783, 0.97764941524251847, 0.9783441685054145])
average_max_fimpact_pred_sim = list(np.mean(np.matrix(max_fimpact_pred_sim), axis=0).A1)

max_recallimpact_pred_sim = []
max_recallimpact_pred_sim.append([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14240343779747952, 0.57419650110247011, 0.65224792138728371, 0.77541722633542742, 0.86559885004619441, 0.94823968944421855, 0.9719527112838241, 0.97188155233024742, 0.97305926751756522, 0.97410735878905097, 0.97210636624443014])
average_max_recallimpact_pred_sim = list(np.mean(np.matrix(max_recallimpact_pred_sim), axis=0).A1)

plain_uncertainty_sampling = []
plain_uncertainty_sampling.append([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15158880692685733, 0.5294299865794657, 0.6202391255296635, 0.7469632159080971, 0.7469632159080971, 0.7469586499409092, 0.7469603142997072, 0.8135861375637903, 0.8461393546286798, 0.9355952763199751, 0.9355148545908893])
average_plain_uncertainty_sampling = list(np.mean(np.matrix(plain_uncertainty_sampling), axis=0).A1)


label_0 = [4, 8, 12, 16, 20, 24, 28, 38, 48, 58, 68, 78, 88, 98, 108, 118, 128, 138, 148, 158, 168, 178, 188, 198, 208, 218, 228, 238, 248, 258, 268, 278, 288, 298, 308, 318, 328, 338, 348, 358, 368, 378]

fscore_metadata_with_extr_number = []
fscore_metadata_with_extr_number.append([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23246281437226621, 0.62996957867112324, 0.7512569987469665, 0.85821501602540862, 0.85821915573232599, 0.85821915573232599, 0.85821915573232599, 0.91816871316559956, 0.91822892358425967, 0.96620006383491508, 0.96620006383491508, 0.96620343078982429, 0.96620679772280194, 0.96620789828499209, 0.94270128847484957, 0.9468071568552594, 0.95707620430781648, 0.95707620430781648, 0.957079489893644, 0.95708606100319449, 0.95709456585774633, 0.97969029145624931, 0.98405406798443418, 0.98832273462653564, 0.98832273462653564, 0.98832273462653564, 0.98851392038538899, 0.98851716019922808, 0.98933545257032252, 0.99030177245677753, 0.98969144887247218, 0.98969144887247218])
fscore_metadata_with_extr_number.append([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23187169137666799, 0.64190759545523146, 0.71746662486717117, 0.82999988857566276, 0.82999988857566276, 0.82999988857566276, 0.82999988857566276, 0.87543450279114265, 0.81600455572021147, 0.89745305079433957, 0.89745305079433957, 0.89744617378071745, 0.89745614087953285, 0.89747004797145824, 0.91221574102739378, 0.97089489516775429, 0.97925866797131489, 0.97925866797131489, 0.97927442794652997, 0.97927771340285819, 0.97928415089481147, 0.98109286408095964, 0.98540428579724737, 0.99015970835030032, 0.99015970835030032, 0.99015977145275635, 0.99018567384118172, 0.99018567384118172, 0.98552068542505811, 0.98703829973369006, 0.98451191056346443, 0.98451191056346443])
fscore_metadata_with_extr_number.append([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043594798475114896, 0.5166695562126018, 0.60862973965316303, 0.73913872102533962, 0.73913872102533962, 0.73913872102533962, 0.73913872102533962, 0.88280199156332095, 0.89175072932410115, 0.98662391470210453, 0.98662391470210453, 0.98657327079758828, 0.98658657885334089, 0.98659988605235793, 0.96947262272435586, 0.96836256162623657, 0.96836256162623657, 0.96836256162623657, 0.96841199217736385, 0.96842445032341373, 0.96866498804296941, 0.98388344008970108, 0.98579555504101823, 0.98579555504101823, 0.98579555504101823, 0.9858082359183804, 0.9858082359183804, 0.98576988645501629, 0.98801383068973492, 0.99193597438975589, 0.99193597438975589, 0.99193597438975589])
fscore_metadata_with_extr_number.append([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048513330540325569, 0.51241796184357902, 0.54063576964815185, 0.68153077657529915, 0.6815361793848399, 0.68154158215010141, 0.68154158215010141, 0.76146471790036163, 0.76508575141092572, 0.90155545034256124, 0.90209561231172242, 0.9020994367364854, 0.9021982077330678, 0.90218795147168895, 0.96784554324350003, 0.96873354332460004, 0.97898588265768682, 0.97898588265768682, 0.97898588265768682, 0.9789613140837724, 0.98003999767003869, 0.97479386453311367, 0.97882114745748039, 0.97889340979719985, 0.97889340979719985, 0.97890322394620233, 0.97908791532655914, 0.97908791532655914, 0.98391682470787856, 0.98623690800357922, 0.98695497527822007, 0.98695497527822007])
fscore_metadata_with_extr_number.append([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.060102074031310078, 0.54736270862172842, 0.62444685250983245, 0.73531012178018251, 0.73531012178018251, 0.73531012178018251, 0.73531012178018251, 0.871065132046698, 0.84151196510747062, 0.92841429909362727, 0.94520435121419655, 0.9452110338186287, 0.94522105756651364, 0.94522773995926368, 0.94040816841361741, 0.96686724587821027, 0.96686724587821027, 0.96686724587821027, 0.96686724587821027, 0.96697805217054011, 0.96697471304493987, 0.97251913851510452, 0.97565549167572774, 0.98587354843700148, 0.98587354843700148, 0.98587363949579565, 0.98571925933567162, 0.98567542129217756, 0.98595742761211813, 0.98690361511770641, 0.98690361511770641, 0.98690361511770641])

average_metadata_with_extr_number = list(np.mean(np.matrix(fscore_metadata_with_extr_number), axis=0).A1)




ranges = [
	      labels_optimum,
          label_0,
		  labels_optimum,
		  labels_optimum
		  ]
list = [
	    average_plain_uncertainty_sampling,
        average_metadata_with_extr_number,
		average_roundrobin_sim,
		average_maxuncertainty_sim
		]
names = ["plain uncertainty sampling",
	     "distinct uncertainty sampling",
	     "unique distinct uncertainty sampling",
		 "min certainty"
		 ]


'''
#compare round robin
ranges = [labels_optimum,
		  label_0
		  ]
list = [
		average_roundrobin_sim,
	    average_metadata_with_extr_number
		]
names = [
		 "round robin",
		 "round robin old"
		 ]
'''
'''
#vergleich random
ranges = [labels_optimum,
		  label_random
		  ]
list = [
		average_random_sim,
	    average_metadata_no_svd_random
		]
names = [
		 "round robin",
		 "round robin old"
		 ]
'''

plot_list_latex(ranges, list, names, "Address", x_max=168)
#plot_list(ranges, list, names, "Address", x_max=168, end_of_round=98)
#plot_integral(ranges, list, names, "Address", x_max=150, x_min=98)
#plot_end(ranges, list, names, "Address", x_max=150, x_min=98)
#plot_integral_latex(ranges, list, names, "Address", x_max=350)
#plot_outperform_latex(ranges, list, names, "Address",0.904, x_max=350)